\documentclass{article}
\usepackage[a4paper,margin=2cm]{geometry}
\usepackage{graphicx}
\usepackage{color}
\usepackage[latin2]{inputenc}

\newcommand{\net}[0]{{\tt .NET}}
\newcommand{\kw}[1]{{\textcolor{kwcolor}{\tt #1}}}

\definecolor{kwcolor}{rgb}{0.2,0.4,0.0}
\definecolor{lgray}{rgb}{0.8,0.8,0.8}

\title{The Nemerle Project Report}
\author{Leszek Pacholski, Micha{\l} Moskal}

\begin{document}
\maketitle

\section{Introduction}

The objective of the Nemerle project is to create a high--level,
general purpose, statically typed programming language. The language supports
object--oriented, functional and imperative programming paradigms.
The functional part is bundled with type inference and pattern matching.

The language was designed for the \net\ since the very beginning.
The design of the \net\ platform had great impact on it.

Another thing worth mentioning here is support for a powerful,
Turing--complete meta--programming system, which is interesting from
both practical and theoretical point of view.

\section{Reasons}

\subsection{Why \net\ ?}

The \net\ platform was chosen because of several
pragmatic reasons. It provides a wide variety of libraries,
has reasonable support for multi--language programming,
provides an efficient runtime environment (including a garbage
collector and Just--In--Time compiler) with the possibility
of generating code on the fly. Last but not least the executable
files generated by the compiler are portable -- they can be used
on several architectures and operating systems using one
of the available implementations of the \net\ platform
(Microsoft \net, Mono, DotGNU, Rotor).

\subsection{Why a new language, from a user perspective?}

The idea that can attract users is the ability of easily
combining object--oriented design with functional implementations.
A user can design an application or a library at the high level using the
familiar model known from C\# but implement the method bodies
in a functional style. This allows for smooth switch from object--oriented
to functional programming paradigm, in areas where it is more applicable.
Moreover the resulting library can be used from other object--oriented
\net\ languages without any additional effort.

Nemerle doesn't force the programmer to use functional paradigm. It provides
easy access to both object--oriented and imperative features. User
can even choose to ignore functional features and program as he would
in C\#, with minor syntactic differences.

Back when the project started two years ago we had a far more ML--like
language than we have today. After a year of extensions, semantic and
syntactic changes we ended up creating something that could be called
Extended C\# with better functional programming support.

One of our goal was to ease code maintenance. We for example consider
type inference helpful here -- the idea is that the information that
can be thought out by the simple type inference algorithm is redundant
anyway and immediately clear to the programmer. And reducing amount
of redundant information clearly helps with program readability, which in
turn helps code maintenance.

Another thing that can help with maintenance is wise use of macros (compiler
extensions provided by the programmer). They
provide a way to avoid repetitive code, which should help both with
readability. Additionally, a macro once tested will always produce correct
code, which one cannot tell about a programmer coding the same SQL 
query execution over and over again.

\subsection{Why a new language, from a computer scientist perspective?}

From the computer scientist point of view the
main reason for creating programming languages is to experiment.

Main areas here was the meta--programming system, type inference
algorithms for class--based object--oriented languages, and programming
language design in general.

Another good reason was to exercise and experiment with {\tt
System.Reflection.Emit}, especially with respect to generation of code
using generics. We actually have found (and reported) quite a few of
limitations there.


\subsection{Type inference with deferral}

One of the outcomes of the project is a novel type inference algorithm
for class based object--oriented languages. It was the topic of Michal
Moskal's MSc thesis.

The main idea behind the algorithm is to defer certain typing actions
(like object member and overload resolution) until enough information
is given.

For example in the following snippet:
\begin{verbatim}
   def call_foo (x) { x.foo () }
   someList.Iter (call_foo)
\end{verbatim}
one cannot easily type \texttt{x.foo} by looking just at the
\texttt{call\_foo} function definition, because there can be
more than one class with a member called \texttt{foo}.

A similar, yet slightly different, example is:
\begin{verbatim}
   def my_add (x, y) { x + y }
   my_add (2, 3)
\end{verbatim}
where the symbol \texttt{+} cannot be resolved without
first guessing \texttt{x} and \texttt{y} types.

However in both examples it is easy to find out the correct
types by looking at how the function is used. So the idea would be
to leave typing actions depending on yet unknown types for later.
They are stored in a queue and executed after typing of method body
is done.

Experimentation shows this works quite well in practice. The need for
type annotations has been greatly reduced. There virtually no cases
where annotations are required on local function parameters.

The type inference algorithm has to take macros into account. For
example the \texttt{foreach} macro needs to known the type of collection
it is iterating over to generate proper code. We resolve this issue
by leaving up to the macro the decision if it has enough information already,
or if it wants to defer parts of its execution for later, when
more typing information is available.

\section{Macros}

Very important outcome of the Nemerle project is a mature meta--programming
system. It features macros -- dynamically loaded compiler modules,
that can transform, generate and analyze programs.

Macros have broad possibilities of interaction with the compiler.
They can alter the parser to extend the syntax of the language.
There are several possibilites here:
\begin{itemize}
\item let macro invocation look like a regular function invocation;
      this is the default, no special rules are required
\item add a EBNF--like rule, for example
\begin{verbatim}
syntax ("return", Optional (expr))
syntax ("if", "(", cond, ")", e1, Optional (";"), "else", e2)
\end{verbatim}
\item add a EBNF--like rule with special {\tt RawToken} parameter,
      which allows a list of lexing symbols to be passed
      to the macro and interpreted in any way, example invocation
      of such a macro would look like this:
\begin{verbatim}
def mydoc = xml <foo bar="baz">Qux<nux/></foo>;
\end{verbatim}
   the tokens after \texttt{xml} are not a valid Nemerle expression
   though they are lexically valid, so macro can process them as it wish
\end{itemize}

Macro can also obtain information about types of objects it is
working on. This can (and should, to provide proper user experience) be 
combined with deferal, as explained later.

As macros are regular Nemerle programs they can read external
files, connect to databases  and in general do almost anything.
This can be useful to for example generat classes from XML Schema,
or to check if given SQL query is valid and what would it return
at compile time (we can connect to the database, execute query, examine
column names and do a rollback).

One important, from both practical and theoretical, feature of the macro 
system is hygiene. It means that the macro system will protect accidential
name clashes between indetifiers introduced by the macro and by the user.
It is however still possible to break hygine if desired -- one example
would be string interpolation macro. It takes a string like 
\texttt{"foo x=\$bar"} and changes it to \texttt{"foo x=" + bar.ToString()}.
Here in the code generated by the macro the symbol \texttt{bar} should
capture name bound in the outer scope.

\subsection{Uses of macros}

Macros are good for implementation of small, domain specific sublanguages
of the host Nemerle language. Example such languages could be
regular expressions, XPath, XML itself, \texttt{printf} and \texttt{scanf}
\%--languages, SQL and so on. The macro can inspect the syntax
at compile time and report any error it finds. Later it can generate code,
or just pass it to some library functions.

Specialized sublanguages are often simpler to use than complex
API, therefore we see ease of implemntation of such languages
one of the main advantages of Nemerle in the Real World setting.

Another important use  are various extensions of the language
-- things expressible in the ``core'' language, but very often
used, therfore deserving a simple syntax. A good example is
the \texttt{foreach} loop, \texttt{using} expression or the
entire assertion system (simple \texttt{assert} macro together
with \texttt{requires}/\texttt{ensures} declarations for
Design by Contract). 

Yet another example is automatic implementation of various
design pattern (like the proxy pattern).

Macro system can be seen as an extended form of 
\textit{Aspect Oriented Programming}. It doesn't limit
itself to certain cut--points, or a limited set of actions
to be performed on the code though -- this can be seen as a 
disadvantage, as it may allow for too much flexibility on
the programmer side. It is however possible to write a set
of macros to restrict functionality to the regular AOP patterns. 


\section{The project}

The main part of the project is undoubtably the compiler.
There are however several releated subprojects that we will
discuss in this section.

\subsection{Compiler and language}

The most important things about the compiler are the
fact that it is bootstraping (which means it is written
in Nemerle and can compile itself) and it uses runtime
generics extensively.

The most recent version of the compiler is 0.9.0 released
on September 14th, 2005. It targets MS .NET August CTP
and Mono 1.1.9. Earlier versions of runtimes are not
supported because of numerous bugs in S.R.E. APIs.

\subsection{Projects using Nemerle}

There are several external projects using Nemerle.

\begin{itemize}
  \item Sioux -- HTTP/application server (founded from the grant)
  \item cs2n -- C\# to Nemerle converter (founded from the grant)
  \item nemish -- Nemerle Interactive Shell
  \item Asper IDE/editor
  \item NAnt build system plugin
  \item RiDL parser and lexer generator
  \item CodeDom generator (ASP.NET support)
  \item Code Completion Engine
  \item IDE integration (VS.NET, \#D, MD)
\end{itemize}


\subsection{Impact and community}

We believe we had some impact on both MS .NET and Mono runtimes
with our bugreports. We have reported several issues in S.R.E.
mostly related to generic code generation. We have also found one
serious bug in static field initialization in generic classes.
Even more issues were reported to the Mono team, as their
runtime is much less mature.

\subsubsection{Community}

We use a mailing list and (since recently) web forum for communication
and general community building. The mailing list has about 70 subscribers.
Our webpage is wiki--based, which makes external user contributions
in the documentation area easy. The contributions do happen.

We have an online issue tracking system. There about 500 issues
total, while 50 are still open.

Micha{\l} Moskal had a course about Nemerle at the Computer Science
Institute. We also have a free, open--for-all, online course,
it started on October 1st and is still running.

\subsection{Performance results}

We have made some experiments regarding performance of various
implementations of functional constructs. In particular we have confirmed
that using the {\tt tail.} CIL instruction prefix degrades performance
on the MS.NET runtime -- note that this wasn't microbenchmark, but
a compiler bootstrap with {\tt tail.} enabled or not.

We also tested several implementations of functional objects. Delegates
(the most obvious choice) were ruled out, because of the performance.
We end up creating abstract generic base class for functional values.
This turned out to work very good in practice.

Another interesting comparison is type--erasure compilation techniques
against runtime generics. We have found the generic version to be up
to 20\% faster (the exact numbers are hard to give here, because moving
bootstrap from non-generic to generic version was a quite lengthy
and painful process with many sub--stages).

\subsection{Future work}

The plans for near future include a 1.0 stable release. This should happen
before the end of 2005. The online course is part of the wider community
building project. The stable release should also help here. We also plan to
work more on tighter IDE integration.

There are also more distant plans of employing some static analysis on
Nemerle sources to prove contracts.

\end{document}

% vim: language=english
